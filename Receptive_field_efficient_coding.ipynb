{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as py\n",
    "\n",
    "#show plots in the notebook\n",
    "%matplotlib inline\n",
    "py.bone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('http://upload.wikimedia.org/math/1/5/1/15102e8092b886d5dbffc343cedb4591.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#Difference of Gaussians helper function, s = Sigma.\n",
    "#Math is broken into segments for legibility in LaTeX\n",
    "def dogCalc(x, y, s, K):\n",
    "    p1 = ((1/(2*math.pi*s*s))*math.exp(-(x*x+y*y)/(2*s*s)))\n",
    "    p2 = ((1/(2*math.pi*K*K*s*s))*math.exp(-(x*x+y*y)/(2*K*K*s*s)))\n",
    "    return p1 - p2\n",
    "\n",
    "def differenceOfGaussians(sizeX = 16, sizeY = 16, sigma = 1.6, K = 5.0):\n",
    "    return [[dogCalc(x-7.5,y-7.5,sigma,K) for x in range(sizeX)] for y in range(sizeY)]\n",
    "dog_filter = differenceOfGaussians()\n",
    "\n",
    "print('mean before centering:',np.mean(dog_filter))\n",
    "dog_filter = np.array(dog_filter)\n",
    "pos_ind = dog_filter >= 0\n",
    "neg_ind = dog_filter < 0\n",
    "pos_sum = np.sum(dog_filter[pos_ind])\n",
    "neg_sum = np.sum(dog_filter[neg_ind])\n",
    "dog_filter[neg_ind] = - pos_sum / neg_sum * dog_filter[neg_ind]\n",
    "dog_filter = list(dog_filter)\n",
    "print('mean after centering:',np.mean(dog_filter))\n",
    "\n",
    "py.imshow(dog_filter)\n",
    "\n",
    "py.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gabor helper function\n",
    "def gaborCalc(x, y, sx, sy, fx, fy):\n",
    "    p1 = (1/(2*math.pi*sx*sy))\n",
    "    p2 = math.exp(-0.5*(((x*x)/(sx*sx))+((y*y)/(sy*sy))))\n",
    "    p3 = math.cos(2*math.pi*(fx*x+fy*y))\n",
    "    return p1 * p2 * p3\n",
    "\n",
    "def gaborFilter(sizeX = 16, sizeY = 16, sx = 2.0, sy = 3.5, fx = 0.2, fy = 0.0):\n",
    "    return [[gaborCalc(x-7.5,y-7.5,sx,sy,fx,fy) for x in range(sizeX)] for y in range(sizeY)]\n",
    "\n",
    "gabor_filter = gaborFilter()\n",
    "\n",
    "print('mean before centering:',np.mean(gabor_filter))\n",
    "gabor_filter = np.array(gabor_filter)\n",
    "pos_ind = gabor_filter >= 0\n",
    "neg_ind = gabor_filter < 0\n",
    "pos_sum = np.sum(gabor_filter[pos_ind])\n",
    "neg_sum = np.sum(gabor_filter[neg_ind])\n",
    "gabor_filter[neg_ind] = - pos_sum / neg_sum * gabor_filter[neg_ind]\n",
    "gabor_filter = list(gabor_filter)\n",
    "print('mean after centering:',np.mean(gabor_filter))\n",
    "\n",
    "py.imshow(gabor_filter)\n",
    "py.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "#img = mpimg.imread('images/2.tiff')\n",
    "#img = mpimg.imread('images/5.tiff')\n",
    "img = mpimg.imread('images/11.tiff')\n",
    "\n",
    "# show the image\n",
    "fig = py.figure(figsize=(18,30))\n",
    "fig.add_subplot(3,1,1)\n",
    "py.imshow(img, cmap=py.cm.Greys_r)\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "#Convolve with the Difference of Gaussians filter\n",
    "#img_DoG = ndimage.convolve(img, dog_filter, mode='reflect', cval=0.0)\n",
    "img_DoG = ndimage.convolve(img.astype(float), dog_filter, mode='reflect', cval=0.0)\n",
    "fig.add_subplot(3,1,2)\n",
    "py.imshow(img_DoG, cmap=py.cm.Greys_r)\n",
    "\n",
    "#Convolve with the gabor filter\n",
    "#img_gabor = ndimage.convolve(img, gabor_filter, mode='reflect', cval=0.0)\n",
    "img_gabor = ndimage.convolve(img.astype(float), gabor_filter, mode='reflect', cval=0.0)\n",
    "fig.add_subplot(3,1,3)\n",
    "py.imshow(img_gabor, cmap=py.cm.Greys_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create histogram to investigate values\n",
    "fig = py.figure(figsize=(16,6))\n",
    "print(type(img_DoG[0,0]))\n",
    "py.hist(img_DoG.reshape((img_DoG.shape[0]*img_DoG.shape[1]),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_natural_patches(img_folder, num_patches = 5000, patch_width = 8, downsample=2):\n",
    "  \"\"\" collects image patches, in the same way as the LGN model, for analysis \n",
    "  the natural images are from a specific folder of 13 .tiff files\"\"\"\n",
    "\n",
    "  from PIL import Image\n",
    "  max_tries = num_patches * 50\n",
    "  image_width = 200\n",
    "  \n",
    "  img_first_patch = 0 # the first patch number accepted from an image\n",
    "  img_first_try = 0 # the first attempt to take a patch from the image\n",
    "  patch_cnt = 0\n",
    "  try_cnt = 0\n",
    "  ds = downsample\n",
    "  w = patch_width * ds\n",
    "  d = w * w\n",
    "  d_final = patch_width * patch_width\n",
    "  avg_filt = np.ones([ds, ds],'float') / ds**2\n",
    "\n",
    "  layer_patch = np.zeros([1,w,w],float)\n",
    "  down_patch = np.zeros([1,patch_width,patch_width],'float')  \n",
    "  patch = np.zeros([d,1],float)\n",
    "  \n",
    "  img_patches = np.zeros([d_final,num_patches],float)\n",
    "\n",
    "  # change the image sampled from\n",
    "  nat_img_cnt = 1  \n",
    "  active = Image.open(img_folder + '/' + str(nat_img_cnt) + '.tiff')\n",
    "  active = np.asarray(active, 'double').transpose()  \n",
    "  # normalizing the activity image\n",
    "  active -= active.mean()\n",
    "  active /= active.std()\n",
    "      \n",
    "  # collect the patches\n",
    "  while patch_cnt < num_patches and try_cnt < max_tries:\n",
    "    try_cnt += 1  # number of total patches attempted\n",
    "\n",
    "    if (try_cnt - img_first_try) > 50000 or \\\n",
    "      (patch_cnt - img_first_patch) > num_patches/12:\n",
    "      # change the image sampled from\n",
    "      nat_img_cnt += 1\n",
    "      active = Image.open(img_folder + '/' + str(nat_img_cnt) + '.tiff')\n",
    "      active = np.asarray(active, 'double').transpose()        \n",
    "      # normalizing the activity image\n",
    "      active -= active.mean()\n",
    "      active /= active.std()\n",
    "      \n",
    "      img_first_patch = patch_cnt\n",
    "      img_first_try = try_cnt\n",
    "      print (float(patch_cnt)/num_patches)\n",
    "    \n",
    "    px = np.random.randint(0,image_width - w)\n",
    "    py = np.random.randint(0,image_width - w)\n",
    "        \n",
    "    layer_patch[0,:,:] = active[px:px+w,py:py+w].copy()\n",
    "    patch_std = layer_patch.std()\n",
    "    \n",
    "    if patch_std > 0.0:\n",
    "      # create the patch vector\n",
    "      # downsample the patch\n",
    "      for x in range(patch_width):\n",
    "        for y in range(patch_width):\n",
    "          down_patch[0,x,y] = np.sum(avg_filt * layer_patch[0,ds*x:ds*x+ds,ds*y:ds*y+ds])      \n",
    "      patch = np.reshape(down_patch, d_final)     \n",
    "      patch = patch - np.mean(patch)         \n",
    "      img_patches[:,patch_cnt] = patch.copy()\n",
    "      patch_cnt += 1\n",
    "  return img_patches\n",
    "        \n",
    "patches_mat = collect_natural_patches('images', num_patches=50000)\n",
    "print(patches_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_patches_mat(pre_patches, show_patch_num = 16, display=True, num_layers=1):\n",
    "  \"\"\" this function generates a 2D array to display image patches \"\"\"\n",
    "\n",
    "  patches = pre_patches\n",
    "    \n",
    "  tot_patches = patches.shape[1]\n",
    "  data_dim = patches.shape[0]\n",
    "  patch_width = np.sqrt(data_dim / num_layers)\n",
    "  \n",
    "  # extract show_patch_num patches\n",
    "  disp_patch = np.zeros([data_dim, show_patch_num], float)\n",
    "  for i in range(0,show_patch_num):\n",
    "    #if i < 5:\n",
    "      # the first 5 patches\n",
    "      #patch_i = i\n",
    "    #elif i < 10:\n",
    "      # spread the samples in the middle\n",
    "    patch_i = i * tot_patches // show_patch_num\n",
    "    #else:\n",
    "      # the last 5 patches\n",
    "      #patch_i = tot_patches - (show_patch_num - i)\n",
    "  \n",
    "    patch = patches[:,patch_i].copy()\n",
    "    pmax  = patch.max()\n",
    "    pmin = patch.min()\n",
    "    # fix patch range from min to max to 0 to 1\n",
    "    if pmax > pmin: \n",
    "      patch = (patch - pmin) / (pmax - pmin)\n",
    "    disp_patch[:,i] = patch.copy()\n",
    "\n",
    "  bw = 5    # border width\n",
    "  pw_y = patch_width\n",
    "  pw_x = patch_width * num_layers + (num_layers-1)*bw\n",
    "  \n",
    "  patches_y = int(np.sqrt(show_patch_num))\n",
    "  patches_x = int(np.ceil(float(show_patch_num) / patches_y))\n",
    "  patch_img = disp_patch.max() * np.ones([(pw_x + bw) * patches_x - bw,\n",
    "    patches_y * (pw_y + bw) - bw], float)\n",
    "  for i in range(0,show_patch_num): \n",
    "    y_i = int(i / patches_y)\n",
    "    x_i = i % patches_y\n",
    "    reshaped = disp_patch[:,i].reshape((num_layers,patch_width,patch_width))\n",
    "    full_patch = np.zeros([pw_x, pw_y], float)\n",
    "    full_patch[0:patch_width,:] = reshaped[0,:,:].copy()\n",
    "    if num_layers == 2:\n",
    "      full_patch[patch_width + bw - 1:2 * patch_width + bw, :] = reshaped[1,:,:].copy()\n",
    "    patch_img[x_i*(pw_x+bw):x_i*(pw_x+bw)+pw_x,y_i*(pw_y+bw):y_i*(pw_y+bw)+pw_y] = full_patch\n",
    "  \n",
    "  if display:\n",
    "    py.bone()\n",
    "    py.imshow(patch_img.T, interpolation='nearest')\n",
    "    py.axis('off')\n",
    "  return patch_img\n",
    "\n",
    "show_patches_mat(patches_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# finding PCA components - from Griffin, David, Josh, and Eva\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn import decomposition\n",
    "\n",
    "#Convert 256x arrays back to 16x16 arrays\n",
    "\n",
    "def delinearize(array):\n",
    "    size = sqrt(len(array))\n",
    "    outarray = []\n",
    "    temp = []\n",
    "    counter = 1\n",
    "    for i in range(len(array)):\n",
    "        if size != counter:\n",
    "            temp.append(array[i])\n",
    "            counter += 1\n",
    "        else:\n",
    "            outarray.append(temp)\n",
    "            temp=[]\n",
    "            counter=1\n",
    "    return outarray\n",
    "\n",
    "def pcaComponents(array, components=10):\n",
    "    pcatemp = decomposition.PCA(n_components=components)\n",
    "    pcafit = pcatemp.fit(array)\n",
    "    print(pcafit.explained_variance_ratio_)   \n",
    "    return pcafit.components_\n",
    "\n",
    "num_components = 20\n",
    "pcacomp = pcaComponents(np.transpose(patches_mat), components = num_components)\n",
    "\n",
    "fig = py.figure(figsize=(15,12))\n",
    "for i in range(num_components):\n",
    "    fig.add_subplot(np.ceil(num_components/5),5,i+1)\n",
    "    py.imshow(delinearize(pcacomp[i]))\n",
    "    py.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def icaComponents(array, components=10):\n",
    "    icatemp = decomposition.FastICA(n_components=components)\n",
    "    #icatemp = decomposition.FastICA(n_components=components, max_iter=500, whiten=False)\n",
    "    return icatemp.fit(array).components_\n",
    "\n",
    "#num_components = 10\n",
    "num_components = 50\n",
    "icacomp = icaComponents(np.transpose(patches_mat), components = num_components)\n",
    "\n",
    "print(icacomp.shape)\n",
    "fig = py.figure(figsize=(15,12))\n",
    "for i in range(num_components):\n",
    "    fig.add_subplot(np.ceil(num_components/5),5,i+1)\n",
    "    py.imshow(delinearize(icacomp[i]))\n",
    "    py.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def icaComponents(array, components=10):\n",
    "    icatemp = decomposition.FastICA(n_components=components)\n",
    "    #icatemp = decomposition.FastICA(n_components=components, max_iter=500, whiten=False)\n",
    "    return icatemp.fit(array).components_\n",
    "\n",
    "pca_components = 50\n",
    "pcatemp = decomposition.PCA(n_components = pca_components)\n",
    "transformed_patch_array = pcatemp.fit_transform(np.transpose(patches_mat))\n",
    "\n",
    "ica_components = 50\n",
    "trans_icacomp = icaComponents(transformed_patch_array, components = ica_components)\n",
    "print(trans_icacomp.shape)\n",
    "\n",
    "ica_comp = pcatemp.inverse_transform(trans_icacomp)\n",
    "\n",
    "fig = py.figure(figsize=(15,12))\n",
    "for i in range(ica_components):\n",
    "    fig.add_subplot(np.ceil(ica_components/5),5,i+1)\n",
    "    py.imshow(delinearize(icacomp[i]))\n",
    "    py.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
